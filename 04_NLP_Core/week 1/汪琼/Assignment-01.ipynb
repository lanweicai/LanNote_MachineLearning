{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 今天是2020年6月11日，今天世界上又多了一名AI工程师 :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 作业截止时间\n",
    "此次作业截止时间为 2020.6.18日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**：每道题是否回答完整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "1、个人助理（智能手机上的语音助理、语音输入、家庭管家和陪护机器人） 产品举例：微软小冰、百度度秘、科大讯飞等、Amazon Echo、Google Home等\n",
    "\n",
    "2、安防（智能监控、安保机器人） 产品举例：商汤科技、格灵深瞳、神州云海\n",
    "\n",
    "3、自驾领域（智能汽车、公共交通、快递用车、工业应用） 产品举例：Google、Uber、特斯拉、亚马逊、奔驰、京东等\n",
    "\n",
    "4、医疗健康（医疗健康的监测诊断、智能医疗设备） 产品举例： Enlitic、Intuitive Sirgical、碳云智能、Promontory等\n",
    "\n",
    "5、电商零售（仓储物流、智能导购和客服） 产品举例：阿里、京东、亚马逊\n",
    "\n",
    "6、金融（智能投顾、智能客服、安防监控、金融监管） 产品举例：蚂蚁金服、交通银行、大华股份、kensho\n",
    "\n",
    "7、教育（智能评测、个性化辅导、儿童陪伴） 产品举例：学吧课堂、科大讯飞、云知声\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "\n",
    "How do we use Github？\n",
    "    \n",
    "1、工具/原料：可上网的电脑、pycharm\n",
    "2、方法/步骤：\n",
    "①打开百度，搜索github，没有注册需要先注册一下。\n",
    "②然后我们新建一个项目。暂时不放文件。\n",
    "③然后我们需要搜索并且下载安装git。\n",
    "④找到我们刚刚的项目，并且复制项目的地址。\n",
    "⑤在pycharm里进行设置，编写好代码以后，点击VCS-GIT。\n",
    "⑥粘贴刚刚的地址，然后打开项目，这个时候就能把项目从github上面拉下来了。\n",
    "⑦我们对项目目录进行文件的添加和修改，然后点击add。并且commit file。\n",
    "⑧最后我们需要push更新的文件到github。\n",
    "⑨刷新一下就能看到我们上传的更新项目了。(来源：百度经验)\n",
    "3、用途：\n",
    "（1）可以学习优秀的开源项目；\n",
    "（2）多人协作\n",
    "（3）搭建博客、个人网站或者公司官网\n",
    "（4）写作\n",
    "（5）提升个人简历等等\n",
    "\n",
    "\n",
    "\n",
    "Why do we use Jupyter and Pycharm？\n",
    "1、Jupyter Notebook：\n",
    "（1）是一个交互式笔记本，它功能强大，支持40多种编程语言，可共享，并提供在同一环境中构建可视化应用的服务。提供了一个环境，用户可以在里面写代码、运行代码、查看结果，并在其中可视化数据。能帮助数据科学家便捷地执行各种端到端任务，如数据清洗、统计建模、构建/训练机器学习模型等。\n",
    "（2）对于初学者，Jupyter Notebook也独具魅力。它的一个特色是允许把代码写入独立的cell中，然后单独执行。这样做意味着用户可以在测试项目时单独测试特定代码块，无需从头开始执行代码。有很强的灵活性和交互性。\n",
    "（3）可以很方便的保存和共享笔记本。做数据分析和机器学习使用这个很方便操作。\n",
    "\n",
    "2、Pycharm：\n",
    "（1）作用：编码协助、项目代码导航、代码分析、Python重构、支持Django、支持Google App引擎、集成版本控制、图形页面调试器、集成的单元测试、可自定义&可扩展。\n",
    "（2）PyCharm 是一种 Python IDE，可以帮助程序员节约时间，提高生产效率。\n",
    "（3）Pycharm 带有一整套可以帮助用户在使用 Python 语言开发时提高其效率的工具，比如调试、语法高亮、项目管理、代码跳转、智能提示、自动完成、单元测试、版本控制。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1、概率模型是用来描述不同随机变量之间关系的数学模型，通常情况下刻画了一个或多个随机变量之间的相互非确定性的概率关系。从数学上讲，该模型通常被表达为 ，其中 Y 是观测集合用来描述可能的观测结果， P 是 Y 对应的概率分布函数集合。若使用概率模型，一般而言需假设存在一个确定的分布P 生成观测数据 Y 。因此通常使用统计推断的办法确定集合 P 中谁是数据产生的原因。\n",
    "   大多数统计检验都可以被理解为一种概率模型。例如，一个比较两组数据均值的学生t检验可以被认为是对该概率模型参数是否为0的检测。此外，检验与模型的另一个共同点则是两者都需要提出假设并且误差在模型中常被假设为正态分布。\n",
    "2、定义：\n",
    "（1）概率模型：是一个概率分布函数或密度函数的集合。可分为参数模型，无参数和半参数模型。\n",
    "（2）参数模型：是一组由有限维参数构成的分布集合。概率模型可被用来描述一组可产生已知采样数据的分布集合。\n",
    "（3）无参数模型：则是一组由无限维参数构成的概率分布函数集合 。\n",
    "相比于无参数模型和参数模型，半参数模型也由无限维参数构成，但其在分布函数空间内并不紧密。\n",
    "3、机器学习常见概率模型：\n",
    "Bernoulli 分布、Multinoulli 分布、高斯分布、指数分布和Laplace 分布、分布的混合\n",
    "4、机器学习中用一类图来表达变量相关关系的概率模型（概率模型将学习任务归结于计算变量的概率分布）\n",
    "P(A|B)=P(A,B)/P(B)——根据联合概率 P(A,B)推断P(A|B)的过程\n",
    "\n",
    "具体说：假定所关心的变量集合为 Y，可观测变量集合为 O，其他变量的集合为 R\n",
    "\n",
    "“生成式”模型：考虑联合分布 P(Y,R,O)\n",
    "\n",
    "”判别式“模型：考虑联合分布 P(Y,R|O)\n",
    "\n",
    "“推断”——利用已知变量推测未知变量的分布——核心是：如何基于可观察变量推测出未知变量的条件分布；\n",
    "\n",
    "          ——给定一组观测变量值，由 P(Y,R,O) 或 P(Y,R|O) 得到条件概率  P(Y|O)\n",
    "\n",
    "已知图模型：①有向图模型——贝叶斯网\n",
    "        ②无向图模型——马尔科夫随机场\n",
    "未知图模型：“评分搜索”——根据训练数据集找出结构最恰当的贝叶斯网"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1、贝叶斯线性回归模型（BLR)：这类模型把线性回归中的系数和截距等参数作为未知的概率分布。\n",
    "2、状态空间模型(State- Space Model, SSM)和隐含马尔科夫模型(Hidden Markov Model, HMM)：这类模型假设在可观测数据背后包含了某种隐含模式，并且可以利用条件概率分布来发掘这些隐含模式来总结数据规律以及预测未来数据。SSM通常用于描述连续的隐含状态，而HMM通常指有限的隐含状态。\n",
    "3、贝叶斯神经网络（BNN)。\n",
    "应用:自动驾驶，人脸识别，期货股票交易预测等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1、Why do we use probability ？\n",
    "   在计算机处理数据之时，对于计算机而言，它处理的每一个词都具有不确定性和随机性。事实上，不管是文字翻译、语音识别还是其他的智能行为，计算机通常都必须处理不确定的变量，这些不确定性通常有3种可能的来源：\n",
    "（一） 被建模系统内在的随机性。例如在一个纸牌游戏中，我们假设纸牌被真正混洗成了随机顺序；\n",
    "（二） 不完全观测。即使是确定的系统，当我们不能完全观测到这个系统的全部变量时，这个系统也呈现随机性。例如在一个游戏节目中，参与者被要求在三个门之间选择，其中两个门背后没有东西，另一个门后放置着一个礼盒。对局外人来说，参与者的每个选择的结果是确定的，但对参与者来说，结果却是不确定的。\n",
    "（三） 不完全建模。当我们使用一些必须舍弃某些观测信息的模型时，舍弃的这些信息会导致模型的预测出现不确定性。\n",
    "   当我们说一个事件A发生的概率是p，那么p代表着什么意思？p意味着如果我们反复进行一个实验无限次，有p的比例可能会发生事件A。这很容易理解，就像掷色子，如果说掷出6点的概率为1/6，那么就是说如果我们反复掷色子一百次一千次，那么掷出6点的次数就会接近掷色子次数的1/6。这便是频率派概率。\n",
    "那么如果一个医生对病人进行诊断之后，说该病人患癌症的概率为30%，这个概率又是什么意思呢？在这个案例中，1表示确定病人患癌症，0表示确定病人没有患癌症，这个便是对确定性水平的一种表示，被称为贝叶斯概率。\n",
    "如果我们将频率派概率和贝叶斯概率视作等同的，那么我们便可以做以下的事情：在一个纸牌游戏中，我们可以根据一个人手上的牌来计算这个人输赢的概率，就像医生根据病人的症状计算病人是否患病的概率一样。\n",
    "\n",
    "2、what's the difficult points for programming based on parsing and pattern match?\n",
    "熟悉算法基础和原理，会用编程实现算法功能。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1、语言模型可以对一段文本的概率进行估计，对信息检索，机器翻译，语音识别等任务有着重要的作用。语言模型分为统计语言模型和神经网络语言模型。\n",
    "2、一个语言模型通常构建为字符串s的概率分布p(s)，这里p(s)试图反映的是字符串s作为一个句子出现的频率。\n",
    "3、有以下特点：\n",
    "一门语言（等价为词典）可以看作是一个发出符号序列的有记忆信源。\n",
    "发出的每种符号序列都是由这门语言构成的一个句子。\n",
    "语言模型是用来描述信源发出符号序列的概率分布的。\n",
    "4、语言模型基本上可以看作是一个句子的概率分布，我们计算句子出现的概率，其实就是在算这个概率分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1、语言模型在自然语言处理中占有重要的地位，尤其在基于统计模型的语音识别、机器翻译、汉语自动分词和句法分析等相关研究中得到了广泛应用。目前主要采用的是n元语法模型（n-gram model），这种模型构建简单、直接，但同时也因为数据缺乏而必须采取平滑算法。\n",
    "2、搜狗拼音和微软拼音的主要思想就是N-gram模型。\n",
    "3、语言模型应用场景：\n",
    "（1）语音识别，不同的单词序列可以有相同的发音，我们就可以通过语言模型来进行判断.\n",
    "（2）句子生成（sentence generation），比如你在设计对话系统的时候，现在有好多句子都可以进行回应，我们就可以用语言模型（language model）选择文法最对的句子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1、N-Gram是大词汇连续语音识别中常用的一种语言模型，对中文而言，我们称之为汉语语言模型(CLM, Chinese Language Model)。汉语语言模型利用上下文中相邻词间的搭配信息，在需要把连续无空格的拼音、笔划，或代表字母或笔划的数字，转换成汉字串(即句子)时，可以计算出具有最大概率的句子，从而实现到汉字的自动转换，无需用户手动选择，避开了许多汉字对应一个相同的拼音(或笔划串，或数字串)的重码问题。\n",
    "\n",
    "2、\n",
    "当N=1时，为一元模型，它是指把句子分成一个一个的汉字。此时，意味着每一个独立的词都是一个独立的模型，与上下文无关。\n",
    "当N=2时，为二元模型，指把句子从头到尾每两个字组成一个词语；\n",
    "当N=3时，为三元模型，指把句子从头到尾每三个字组成一个词语。\n",
    "\n",
    "3、对于1-gram，其假设是：\n",
    "$$P(w_n|w_1w_2…w_{n-1})≈P(w_n|w_{n-1})$$\n",
    "\n",
    "对于2-gram，其假设是：\n",
    "$$P(w_n|w_1w_2…w_{n-1})≈P(w_n|w_{n-1},w_{n-2})$$\n",
    "  \n",
    "对于3-gram，其假设是：\n",
    "$$P(w_n|w_1w_2…w_{n-1})≈P(w_n|w_{n-1},w_{n-2},w_{n-3})$$\n",
    " \n",
    "依次类推。因此，\n",
    "在1-gram模型下：\n",
    "\n",
    "$$P(w_1, w_2, w_3, … , w_n)=P(w_1)P(w_2|w_1)P(w_3|w_1w_2)P(w_4|w_1w_2w_3)…P(w_n|w_1w_2…w_{n-1})\n",
    "≈P(w_1)P(w_2|w_1)P(w_3|w_2)P(w_4|w_3)…P(w_n|w_{n-1})$$\n",
    "\n",
    "在2-gram模型下：\n",
    "\n",
    "$$P(w_1, w_2, w_3, … , w_n)=P(w_1)P(w_2|w_1)P(w_3|w_1w_2)P(w_4|w_1w_2w_3)…P(w_n|w_1w_2…w_{n-1})\n",
    "≈P(w_1)P(w_2|w_1)P(w_3|w_1w_2)P(w_4|w_2w_3)…P(w_n|w_{n-2}w_{n-1})$$\n",
    "\n",
    "在3-gram模型下：\n",
    "\n",
    "$$P(w_1, w_2, w_3, … , w_n)=P(w_1)P(w_2|w_1)P(w_3|w_1w_2)P(w_4|w_1w_2w_3)…P(w_n|w_1w_2…w_{n-1})\n",
    "≈P(w_1)P(w_2|w_1)P(w_3|w_1w_2)P(w_4|w_1w_2w_3)…P(w_n|w_{n-3}w_{n-2}w_{n-1})$$\n",
    "\n",
    "假设我们采用的是1-gram模型，那么：\n",
    "P(I,have,a,gun)=P(I)P(have|I)P(a|have)P(gun|a).\n",
    "然后，我们再用“数数”的方法求P(I)和其他的三个条件概率：\n",
    "P(I)=语料库中I出现的次数 / 语料库中的总词数\n",
    "P(have|I) = 语料库中I和have一起出现的次数 / 语料库中I出现的次数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "   N-gram模型的优点在于它包含了前N-1个词所能提供的全部信息，这些词对于当前词的出现具有很强的约束力，然而它的缺点是需要相当规模的训练文本来确定模型的参数。当N很大时，模型的参数空间过大。所以常见的N值一般为1,2。还有因数据稀疏而导致的数据平滑问题，解决方法主要是使所有的N-gram概率之和为1和使所有的N-gram概率都不为0.\n",
    "\n",
    "   除此之外，与连续空间的词表示法语言学规则模型对比（例如word2vec构建出的词向量），N-gram语言模型还有以下的局限性：\n",
    "\n",
    "   N-gram模型是根据相互之间没有任何遗传属性的离散单元词而构建，从而不具备连续空间中的词向量所满足的语义上的优势：相似意义的词语具有相似的词向量，从而当系统模型针对某一词语或词序列调整参数时，相似意义的词语和词序列也会发生改变。\n",
    "\n",
    "   因此，如果在已知关键词权重非常大的情况下，使用N-gram模型或许比较合适。\n",
    "   \n",
    "1_gram:\n",
    "   当n越小时，模型只考虑领近词语之间的关系。尤其是对于n=1时的特殊情况，被称之为unigram，此时对于每一个词的概率评估实际上与文本的上下文无关，仅与当前词语在语料库中出现的概率有关，但人们不会以一个词一个词的方式交流，而是要以词组成句子和段落，所以要预测一个词是否出现，需要考虑上下文中的更多词，即增大n 的取值，以捕捉更多的有用信息。\n",
    "   缺陷：忽视了词间的语义信息。\n",
    "   低阶n-gram考虑非常有限的上下文信息，但是具有更强的鲁棒性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "   2-gram是N-gram模型里的二元语法模型，又叫一阶马尔科夫链。\n",
    "   为了解决数据稀疏和计算代价大的问题，需要使用马尔可夫假设来简化语言模型，给定时间线上有一串事件顺序发生，假设每个事件的发生概率只取决于前一个事件，那么这串事件构成的因果链被称作马尔可夫链。\n",
    "   在语言模型中，第 t 个事件指的是Wt作为第t给单词出现，也就是说，每个单词出现的概率只取决于前一个单词：\n",
    "   $$p(w_t|w_0w_1...w_{t-1})=p(w_t|w_{t-1})$$\n",
    "   \n",
    "   基于此假设，式子一下子变短了不少，此时的语言模型称为二元语法模型：\n",
    "   $$p(w)=p(w_0w_1w_2w_3...w_k)\n",
    "      =\\quad \\prod_{t=1}^{k+1} p(w_t|w_{t-1})\\quad$$\n",
    "   由于语料库中二元连续的重复程度要高于整个句子的重要程度，所以缓解了数据稀疏的问题，另外二元连续的总数量远远小于句子的数量，存储和查询也得到了解决。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1591874519607&di=bdfbf39f8e79a36f840936002404d5fb&imgtype=0&src=http%3A%2F%2Fwestworldwatchers.com%2Fwp-content%2Fuploads%2F2018%2F03%2FDolores-and-Teddy-Westworld-1.jpg)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "三国= '''\n",
    "三国 ->  开篇 人物  地点  活动  人物1 结尾\n",
    "开篇 -> 特大新闻！ | 劲爆消息！ | 头条头条！\n",
    "人物 -> 曹操 | 刘备 | 周瑜 | 孙权 | 诸葛亮 | 司马懿\n",
    "地点 -> 在濮阳 | 在荆州 | 在白马坡 | 在幽州 | 在洛阳\n",
    "活动 -> 思念 | 算计 | 对峙 | 熬死 | 投奔 | 擒杀\n",
    "人物1 -> 人物 和 人物 | 人物1\n",
    "结尾 -> !!!\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**： 是否提出了和课程上区别较大的语法结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "管家 =\"\"\"\n",
    "管家 -> 招呼  介绍  询问  活动  结尾\n",
    "招呼 -> 您好！  称谓  | 你好！  称谓\n",
    "称谓 -> 先生 | 女士 | 小姐姐 | 小妹妹\n",
    "介绍 ->，我是您的 职业 ，\n",
    "职业 -> 专属管家 | 贴身保镖  |  跟班 | 助手\n",
    "询问 -> 请问您需要 | 您想要 | 您打算\n",
    "活动 -> 让我为您  服务\n",
    "服务 -> 端茶 | 倒水 | 提行李 |  做饭 | 写作业\n",
    "结尾 -> 吗？\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**：是否和上一个语法区别比较大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_grammar(grammar_str:str):\n",
    "    \n",
    "    grammar = {}\n",
    "    \n",
    "    for line in grammar_str.split('\\n'):\n",
    "        if not line:continue\n",
    "        expr,formulas = line.split('->')\n",
    "        grammar[expr.strip()] = [s.split() for s in formulas.split('|')]\n",
    "        \n",
    "    return grammar\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genarate_by_grammar(grammar:dict,target=str):\n",
    "    if target not in grammar:return target\n",
    "    expr = random.choice(grammar[target])\n",
    "    return ''.join(genarate_by_grammar(grammar,t) for t in expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'头条头条！曹操在幽州对峙孙权和曹操!!!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genarate_by_grammar(grammar=generate_grammar(三国),target='三国')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好！小妹妹，我是您的助手，请问您需要让我为您端茶吗？'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genarate_by_grammar(grammar=generate_grammar(管家),target='管家')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "头条头条！曹操在荆州投奔周瑜和孙权!!! \n",
      "\n",
      "头条头条！周瑜在濮阳擒杀诸葛亮和曹操!!! \n",
      "\n",
      "头条头条！曹操在濮阳擒杀刘备和司马懿!!! \n",
      "\n",
      "头条头条！司马懿在洛阳投奔孙权和司马懿!!! \n",
      "\n",
      "劲爆消息！孙权在洛阳投奔司马懿和司马懿!!! \n",
      "\n",
      "头条头条！周瑜在白马坡投奔周瑜和孙权!!! \n",
      "\n",
      "头条头条！孙权在荆州投奔孙权和诸葛亮!!! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_n(grammar,target,n=7):    \n",
    "    for i in range(n):        \n",
    "        print(genarate_by_grammar(grammar,target),'\\n')\n",
    "generate_n(generate_grammar(三国),target='三国',n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！先生，我是您的助手，您打算让我为您倒水吗？ \n",
      "\n",
      "您好！女士，我是您的专属管家，您想要让我为您做饭吗？ \n",
      "\n",
      "你好！小妹妹，我是您的助手，您打算让我为您提行李吗？ \n",
      "\n",
      "你好！女士，我是您的贴身保镖，您打算让我为您写作业吗？ \n",
      "\n",
      "您好！女士，我是您的跟班，您想要让我为您倒水吗？ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_n(grammar,target,n=5):    \n",
    "    for i in range(n):        \n",
    "        print(genarate_by_grammar(grammar,target),'\\n')\n",
    "generate_n(generate_grammar(管家),target='管家',n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**; 运行代码，观察是否能够生成多个句子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 C 中的卷是 Windows \n",
      " 卷的序列号是 709F-EA84\n",
      "\n",
      " C:\\Users\\Jessica\\Downloads\\归档 的目录\n",
      "\n",
      "2020/06/18  15:35    <DIR>          .\n",
      "2020/06/18  15:35    <DIR>          ..\n",
      "2020/06/17  22:17    <DIR>          .ipynb_checkpoints\n",
      "2020/06/15  13:39            29,176 assignment-01-optional-pattern-match.ipynb\n",
      "2020/06/18  15:35            46,464 Assignment-01.ipynb\n",
      "2020/06/17  11:52            91,421 lesson-01-course-code（00）.ipynb\n",
      "2020/06/17  21:29        46,833,745 movie_comments(1).csv\n",
      "2020/06/17  21:29         1,660,053 train(2).txt\n",
      "2020/06/17  19:42             6,021 Untitled.ipynb\n",
      "2020/06/18  14:42             2,685 Untitled1.ipynb\n",
      "2020/06/11  18:37    <DIR>          __MACOSX\n",
      "               7 个文件     48,669,565 字节\n",
      "               4 个目录 86,866,542,592 可用字节\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = open('train(2).txt','r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1343520"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 ++$++ disability-insurance ++$++ 法律要求残疾保险吗？ ++$++ Is  Disability  Insurance  Required  By  Law?\\n1 ++$++ life-insurance ++$++ 债权人可以在死后人寿保险吗？ ++$++ Can  Creditors  Take  Life  Insurance  After  Death?\\n2 ++$++ renters-insurance ++$++ 旅行者保险有租赁保险吗？ ++$++ Does  Travelers  Insurance  Have  Renters  Insurance?\\n3 ++$++ auto-insurance ++$++ 我可以开一辆没有保险的新车吗？ ++$++ Can  I  Drive  A  New  Car  Home  Without  Insurance?\\n4 ++$++ life-insurance ++$++ 人寿保险的现金转出价值是否应纳税？ ++$++ Is  The  Cash  Surrender  Value  Of '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "法律要求残疾保险吗债权人可以在死后人寿保险吗旅行者保险有租赁保险吗我可以开一辆没有保险的新车吗人寿保险的现金转出价值是否应纳税如何报告年金收入家庭保险涵盖什么什么是简单的退休计划社会保险残疾保险是什么\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "train_n = re.sub(u\"([^\\u4e00-\\u9fa5])\", \"\", train)\n",
    "\n",
    "print(train_n[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "def cut(string):\n",
    "    return list(jieba.cut(string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Jessica\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.897 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['法律', '要求', '残疾', '保险', '吗', '债权人', '可以', '在', '死', '后']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train=cut(train_n)\n",
    "all_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('保险', 5005), ('的', 3220), ('人寿保险', 2962), ('什么', 2675), ('吗', 2479), ('是', 2344), ('我', 2053), ('是否', 1862), ('可以', 1704), ('健康', 1513)]\n",
      "[('健康保险', 1347), ('什么是', 1152), ('保险是否', 975), ('我的', 726), ('残疾保险', 658), ('房主保险', 602), ('我可以', 530), ('保险吗', 511), ('是否覆盖', 504), ('家庭保险', 440)]\n",
      "74259\n",
      "74258\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter(all_train)\n",
    "\n",
    "train_2_gram= [''.join(all_train[i:i+2]) for i in range(len(all_train[:-1]))]\n",
    "\n",
    "word_count_2 = Counter(train_2_gram)\n",
    "\n",
    "print(word_counts.most_common(10))\n",
    "print(word_count_2.most_common(10))\n",
    "\n",
    "print(len(all_train))\n",
    "print(len(train_2_gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['法律', '要求', '残疾', '保险', '吗', '债权人', '可以', '在', '死', '后']\n",
      "['法律要求', '要求残疾', '残疾保险', '保险吗', '吗债权人', '债权人可以', '可以在', '在死', '死后', '后人寿保险']\n"
     ]
    }
   ],
   "source": [
    "print(all_train[:10])\n",
    "print(train_2_gram[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word1, word2):\n",
    "    combine = word1 + word2\n",
    "    if combine in word_count_2:\n",
    "        return word_count_2[combine] / word_counts[word2]\n",
    "    else:  \n",
    "        return 1 / len(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09523809523809523"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('保险','法律')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049689440993788817"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('保险','人寿')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_frequences= min([f for w, f in word_counts.most_common()])\n",
    "\n",
    "def prob_1(word):\n",
    "    if word in word_counts: \n",
    "        return word_counts[word] / len(all_train)\n",
    "    else:\n",
    "        return min_frequences / len(all_train)\n",
    "\n",
    "\n",
    "def _2_gram(sentence):\n",
    "    words = cut(sentence)\n",
    "    \n",
    "    prob = 1\n",
    "    \n",
    "    for i in range(len(words)-1):\n",
    "        word,next_word = words[i],words[i+1]\n",
    "        \n",
    "        prob *=prob_2(word,next_word)\n",
    "        \n",
    "    prob *= prob_1(words[-1])\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.141508936945866e-12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2_gram('我可以开一辆没有保险的新车吗')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr(您好！小姐姐，我是您的专属管家，请问您需要让我为您倒水吗？) = 4.03105006036621e-67\n",
      "Pr(你好！小姐姐，我是您的专属管家，您想要让我为您提行李吗？) = 1.9566148436341712e-67\n",
      "Pr(您好！小妹妹，我是您的贴身保镖，您打算让我为您做饭吗？) = 2.242729669949201e-65\n",
      "Pr(你好！小姐姐，我是您的跟班，您想要让我为您倒水吗？) = 7.840582926142408e-62\n",
      "Pr(您好！小妹妹，我是您的贴身保镖，您想要让我为您提行李吗？) = 1.9566148436341712e-67\n",
      "Pr(你好！小妹妹，我是您的跟班，您想要让我为您端茶吗？) = 7.840582926142408e-62\n",
      "Pr(你好！小姐姐，我是您的贴身保镖，您想要让我为您倒水吗？) = 2.242729669949201e-65\n",
      "Pr(您好！女士，我是您的跟班，您打算让我为您倒水吗？) = 7.840582926142408e-62\n",
      "Pr(你好！小姐姐，我是您的专属管家，请问您需要让我为您提行李吗？) = 3.516791385616974e-69\n",
      "Pr(你好！女士，我是您的专属管家，您想要让我为您提行李吗？) = 1.9566148436341712e-67\n"
     ]
    }
   ],
   "source": [
    "for s in [genarate_by_grammar(grammar=generate_grammar(管家),target='管家') for i in range(10)]:\n",
    "    print('Pr({}) = {}'.format(s,_2_gram(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点** 1. 是否使用了新的数据集； 2. csv(txt)数据是否正确解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(grammar,target,model,n): \n",
    "    ss = [genarate_by_grammar(generate_grammar(grammar),target) for i in range(n)]\n",
    "    prob = [model(s) for s in ss]\n",
    "    sens = enumerate(prob)\n",
    "    sens_sorted = sorted(sens,key=lambda x: x[1],reverse = True)\n",
    "    return ss[sens_sorted[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好！小姐姐，我是您的跟班，您想要让我为您做饭吗？'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(管家,'管家',_2_gram,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**： 是否使用 lambda 语法进行排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:1、数据量不够大，数据量最好越大越好，且只是保险行业的，很多其他行业的词汇很少或者没有，此时使用现有模型会有局限性。\n",
    "2、提升：增加数据量或者增加其他环境语料库\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**评阅点**: 是否提出了比较实际的问题，例如OOV问题，例如数据量，例如变成 3-gram问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: minchiuan@zju.edu.cn 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
